{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r-Mb7bnoaRLM"
   },
   "source": [
    "# Логичтическая регрессия, метод опорных векторов, one-hot кодирование"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pNyXo3CvaRLP"
   },
   "source": [
    "### О задании\n",
    "\n",
    "В этом задании вы изучите методы работы с категориальными переменными"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "ndj090dOaRLQ",
    "outputId": "fdef6337-1efe-4945-d445-fb17c46dcc4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%pylab is deprecated, use %matplotlib inline and import the required libraries.\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1_wS0x7RaRLR"
   },
   "source": [
    "__Задание 1.__ Обучение логистической регрессии на реальных данных и оценка качества классификации.\n",
    "\n",
    "**(2 балла)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "94eHa5RgaRLS"
   },
   "source": [
    "Загрузим данные с конкурса [Kaggle Porto Seguro’s Safe Driver Prediction](https://www.kaggle.com/c/porto-seguro-safe-driver-prediction) (вам нужна только обучающая выборка). Задача состоит в определении водителей, которые в ближайший год воспользуются своей автомобильной страховкой (бинарная классификация). Но для нас важна будет не сама задача, а только её данные. При этом под нужды задания мы немного модифицируем датасет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true,
    "id": "BJQn-94DaRLS"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('train.csv', index_col=0)\n",
    "target = data.target.values\n",
    "data = data.drop('target', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u2Su7GNhaRLT"
   },
   "source": [
    "Пересемплируем выборку так, чтобы положительных и отрицательных объектов в выборке было одинаковое число. Разделим на обучающую и тестовую выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true,
    "id": "fot9A7L8aRLT"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(910)\n",
    "\n",
    "def create_balanced_dataset(data, target, samples_per_class=100000):\n",
    "    class_1_idx = np.where(target == 1)[0]\n",
    "    class_0_idx = np.where(target == 0)[0]\n",
    "    \n",
    "    selected_1 = np.random.choice(class_1_idx, samples_per_class, replace=True)\n",
    "    selected_0 = np.random.choice(class_0_idx, samples_per_class, replace=True)\n",
    "    \n",
    "    combined_data = pd.concat([data.iloc[selected_1], data.iloc[selected_0]])\n",
    "    combined_target = np.hstack([target[selected_1], target[selected_0]])\n",
    "    \n",
    "    return combined_data, combined_target\n",
    "\n",
    "data, target = create_balanced_dataset(data, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6GB0kVSoaRLT"
   },
   "source": [
    "Не забудьте отнормировать признаки (можно воспользоваться StandardScaler или сделать это вручную). Пока не будем обращать внимание на то, что некоторые признаки категориальные (этим мы займёмся позже)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true,
    "id": "5dDctZhDaRLU"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ps_ind_01</th>\n",
       "      <th>ps_ind_02_cat</th>\n",
       "      <th>ps_ind_03</th>\n",
       "      <th>ps_ind_04_cat</th>\n",
       "      <th>ps_ind_05_cat</th>\n",
       "      <th>ps_ind_06_bin</th>\n",
       "      <th>ps_ind_07_bin</th>\n",
       "      <th>ps_ind_08_bin</th>\n",
       "      <th>ps_ind_09_bin</th>\n",
       "      <th>ps_ind_10_bin</th>\n",
       "      <th>...</th>\n",
       "      <th>ps_calc_11</th>\n",
       "      <th>ps_calc_12</th>\n",
       "      <th>ps_calc_13</th>\n",
       "      <th>ps_calc_14</th>\n",
       "      <th>ps_calc_15_bin</th>\n",
       "      <th>ps_calc_16_bin</th>\n",
       "      <th>ps_calc_17_bin</th>\n",
       "      <th>ps_calc_18_bin</th>\n",
       "      <th>ps_calc_19_bin</th>\n",
       "      <th>ps_calc_20_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.998215</td>\n",
       "      <td>1.366550</td>\n",
       "      <td>4.483870</td>\n",
       "      <td>0.429490</td>\n",
       "      <td>0.502265</td>\n",
       "      <td>0.351100</td>\n",
       "      <td>0.295375</td>\n",
       "      <td>0.175920</td>\n",
       "      <td>0.177605</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>...</td>\n",
       "      <td>5.443865</td>\n",
       "      <td>1.443745</td>\n",
       "      <td>2.873590</td>\n",
       "      <td>7.544455</td>\n",
       "      <td>0.123355</td>\n",
       "      <td>0.630875</td>\n",
       "      <td>0.553405</td>\n",
       "      <td>0.287530</td>\n",
       "      <td>0.345000</td>\n",
       "      <td>0.152800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.017199</td>\n",
       "      <td>0.674421</td>\n",
       "      <td>2.739255</td>\n",
       "      <td>0.496689</td>\n",
       "      <td>1.501934</td>\n",
       "      <td>0.477315</td>\n",
       "      <td>0.456212</td>\n",
       "      <td>0.380753</td>\n",
       "      <td>0.382181</td>\n",
       "      <td>0.021674</td>\n",
       "      <td>...</td>\n",
       "      <td>2.342462</td>\n",
       "      <td>1.201163</td>\n",
       "      <td>1.692875</td>\n",
       "      <td>2.745287</td>\n",
       "      <td>0.328845</td>\n",
       "      <td>0.482569</td>\n",
       "      <td>0.497141</td>\n",
       "      <td>0.452612</td>\n",
       "      <td>0.475369</td>\n",
       "      <td>0.359796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ps_ind_01  ps_ind_02_cat      ps_ind_03  ps_ind_04_cat  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean        1.998215       1.366550       4.483870       0.429490   \n",
       "std         2.017199       0.674421       2.739255       0.496689   \n",
       "min         0.000000      -1.000000       0.000000      -1.000000   \n",
       "25%         0.000000       1.000000       2.000000       0.000000   \n",
       "50%         1.000000       1.000000       4.000000       0.000000   \n",
       "75%         3.000000       2.000000       7.000000       1.000000   \n",
       "max         7.000000       4.000000      11.000000       1.000000   \n",
       "\n",
       "       ps_ind_05_cat  ps_ind_06_bin  ps_ind_07_bin  ps_ind_08_bin  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean        0.502265       0.351100       0.295375       0.175920   \n",
       "std         1.501934       0.477315       0.456212       0.380753   \n",
       "min        -1.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       1.000000       1.000000       0.000000   \n",
       "max         6.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "       ps_ind_09_bin  ps_ind_10_bin  ...     ps_calc_11     ps_calc_12  \\\n",
       "count  200000.000000  200000.000000  ...  200000.000000  200000.000000   \n",
       "mean        0.177605       0.000470  ...       5.443865       1.443745   \n",
       "std         0.382181       0.021674  ...       2.342462       1.201163   \n",
       "min         0.000000       0.000000  ...       0.000000       0.000000   \n",
       "25%         0.000000       0.000000  ...       4.000000       1.000000   \n",
       "50%         0.000000       0.000000  ...       5.000000       1.000000   \n",
       "75%         0.000000       0.000000  ...       7.000000       2.000000   \n",
       "max         1.000000       1.000000  ...      18.000000       8.000000   \n",
       "\n",
       "          ps_calc_13     ps_calc_14  ps_calc_15_bin  ps_calc_16_bin  \\\n",
       "count  200000.000000  200000.000000   200000.000000   200000.000000   \n",
       "mean        2.873590       7.544455        0.123355        0.630875   \n",
       "std         1.692875       2.745287        0.328845        0.482569   \n",
       "min         0.000000       0.000000        0.000000        0.000000   \n",
       "25%         2.000000       6.000000        0.000000        0.000000   \n",
       "50%         3.000000       7.000000        0.000000        1.000000   \n",
       "75%         4.000000       9.000000        0.000000        1.000000   \n",
       "max        13.000000      22.000000        1.000000        1.000000   \n",
       "\n",
       "       ps_calc_17_bin  ps_calc_18_bin  ps_calc_19_bin  ps_calc_20_bin  \n",
       "count   200000.000000   200000.000000   200000.000000   200000.000000  \n",
       "mean         0.553405        0.287530        0.345000        0.152800  \n",
       "std          0.497141        0.452612        0.475369        0.359796  \n",
       "min          0.000000        0.000000        0.000000        0.000000  \n",
       "25%          0.000000        0.000000        0.000000        0.000000  \n",
       "50%          1.000000        0.000000        0.000000        0.000000  \n",
       "75%          1.000000        1.000000        1.000000        0.000000  \n",
       "max          1.000000        1.000000        1.000000        1.000000  \n",
       "\n",
       "[8 rows x 57 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def normalize_features(df):\n",
    "    standard_scaler = StandardScaler()\n",
    "    normalized_array = standard_scaler.fit_transform(df)\n",
    "    return pd.DataFrame(normalized_array, columns=df.columns)\n",
    "\n",
    "scaled_features = normalize_features(data)\n",
    "scaled_features.describe()\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mSrjeimpaRLU"
   },
   "source": [
    "Обучите логистическую регрессию с удобными для вас параметрами, примените регуляризацию, найдтие оптимум. Сделайте предсказание на тестовой части выборки. Замерьте качество."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true,
    "id": "A1tEHyNFaRLU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5890\n",
      "Precision: 0.5981\n",
      "Recall: 0.5460\n",
      "F1: 0.5709\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def evaluate_model(X_tr, y_tr, X_te, y_te):\n",
    "    lr_model = LogisticRegression(max_iter=1000)\n",
    "    lr_model.fit(X_tr, y_tr)\n",
    "    predictions = lr_model.predict(X_te)\n",
    "    acc = accuracy_score(y_te, predictions)\n",
    "    prec = precision_score(y_te, predictions)\n",
    "    rec = recall_score(y_te, predictions)\n",
    "    f1 = f1_score(y_te, predictions)\n",
    "    return [acc, prec, rec, f1]\n",
    "\n",
    "def display_metrics(metrics):\n",
    "    print(f\"Accuracy: {metrics[0]:.4f}\")\n",
    "    print(f\"Precision: {metrics[1]:.4f}\")\n",
    "    print(f\"Recall: {metrics[2]:.4f}\")\n",
    "    print(f\"F1: {metrics[3]:.4f}\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(normalized_data, target, test_size=0.7)\n",
    "\n",
    "display_metrics(evaluate_model(X_train, y_train, X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N9UQ31XFaRLU"
   },
   "source": [
    "__Выводы__ в свободной форме:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель LogisticRegression (логистической регрессии) уже из коробки предоставляет нам довольно неплохие результаты. Остается правильно отрегулировать и правильно настроить, чтобы повысить эффективность модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rTUVvmreaRLV"
   },
   "source": [
    "__Задание 2.__ Изучение влияния регуляризатора на процесс обучения\n",
    "\n",
    "__(2 балла)__\n",
    "\n",
    "Проверьте на практике, как влияет регуляризатор на процесс обучения (убывание функции потерь на обучающей и отложенной выборках). Чтобы считать функцию потерь на отложенной выборке после каждой итерации, запускайте процесс обучения логистической регрессии с параметром $max\\_iter=1$ и $w^{(0)}$, полученным на предыдущей итерации. Постройте два графика: на одном из них логистическая регрессия с коэффициентом регуляризации, равным 0, а на другом с некоторым разумным значением. На каждом графике одновременно должна быть и функция потерь для обучающей, и для тестовой выборки. Не забудьте сделать одинаковыми оси обоих графиков. Какие выводы вы можете сделать?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "k4YkmjpIaRLV"
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# ...fds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SP-lz7NxaRLV"
   },
   "source": [
    "__Выводы:__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lHvrjAQnaRLW"
   },
   "source": [
    "## Часть 2. Работа с категориальными переменными"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_doKeEKxaRLW"
   },
   "source": [
    "В этой части мы научимся обрабатывать категориальные переменные, так как закодировать их в виде чисел недостаточно (это задаёт некоторый порядок, которого на категориальных переменных может и не быть). Существует два основных способа обработки категориальных значений:\n",
    "- One-hot-кодирование\n",
    "- Счётчики (CTR, mean-target кодирование, ...) — каждый категориальный признак заменяется на среднее значение целевой переменной по всем объектам, имеющим одинаковое значение в этом признаке.\n",
    "\n",
    "Начнём с one-hot-кодирования. Допустим наш категориальный признак $f_j(x)$ принимает значения из множества $C=\\{c_1, \\dots, c_m\\}$. Заменим его на $m$ бинарных признаков $b_1(x), \\dots, b_m(x)$, каждый из которых является индикатором одного из возможных категориальных значений:\n",
    "$$\n",
    "b_i(x) = [f_j(x) = c_i]\n",
    "$$\n",
    "\n",
    "__Задание 1.__ Закодируйте все категориальные признаки с помощью one-hot-кодирования. Обучите логистическую регрессию и посмотрите, как изменилось качество модели (с тем, что было ранее). Измерьте время, потребовавшееся на обучение модели.\n",
    "\n",
    "__(3 балла)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "GC4tPzPbaRLW"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ps_ind_01</th>\n",
       "      <th>ps_ind_03</th>\n",
       "      <th>ps_ind_06_bin</th>\n",
       "      <th>ps_ind_07_bin</th>\n",
       "      <th>ps_ind_08_bin</th>\n",
       "      <th>ps_ind_09_bin</th>\n",
       "      <th>ps_ind_10_bin</th>\n",
       "      <th>ps_ind_11_bin</th>\n",
       "      <th>ps_ind_12_bin</th>\n",
       "      <th>ps_ind_13_bin</th>\n",
       "      <th>...</th>\n",
       "      <th>ps_car_11_cat_0.9698844814339967</th>\n",
       "      <th>ps_car_11_cat_0.9999078260160954</th>\n",
       "      <th>ps_car_11_cat_1.0299311705981942</th>\n",
       "      <th>ps_car_11_cat_1.0599545151802927</th>\n",
       "      <th>ps_car_11_cat_1.0899778597623915</th>\n",
       "      <th>ps_car_11_cat_1.1200012043444902</th>\n",
       "      <th>ps_car_11_cat_1.1500245489265888</th>\n",
       "      <th>ps_car_11_cat_1.1800478935086876</th>\n",
       "      <th>ps_car_11_cat_1.210071238090786</th>\n",
       "      <th>ps_car_11_cat_1.2400945826728849</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.000000e+05</td>\n",
       "      <td>2.000000e+05</td>\n",
       "      <td>2.000000e+05</td>\n",
       "      <td>2.000000e+05</td>\n",
       "      <td>2.000000e+05</td>\n",
       "      <td>2.000000e+05</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>2.000000e+05</td>\n",
       "      <td>2.000000e+05</td>\n",
       "      <td>2.000000e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.00000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-4.661160e-17</td>\n",
       "      <td>1.601563e-16</td>\n",
       "      <td>-4.462208e-17</td>\n",
       "      <td>4.348522e-17</td>\n",
       "      <td>6.785683e-17</td>\n",
       "      <td>-1.007550e-16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.046363e-17</td>\n",
       "      <td>-4.220624e-17</td>\n",
       "      <td>-6.252776e-18</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005090</td>\n",
       "      <td>0.003105</td>\n",
       "      <td>0.00319</td>\n",
       "      <td>0.004255</td>\n",
       "      <td>0.016775</td>\n",
       "      <td>0.009200</td>\n",
       "      <td>0.012870</td>\n",
       "      <td>0.003385</td>\n",
       "      <td>0.035640</td>\n",
       "      <td>0.159235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000003e+00</td>\n",
       "      <td>1.000003e+00</td>\n",
       "      <td>1.000003e+00</td>\n",
       "      <td>1.000003e+00</td>\n",
       "      <td>1.000003e+00</td>\n",
       "      <td>1.000003e+00</td>\n",
       "      <td>1.000003</td>\n",
       "      <td>1.000003e+00</td>\n",
       "      <td>1.000003e+00</td>\n",
       "      <td>1.000003e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071163</td>\n",
       "      <td>0.055636</td>\n",
       "      <td>0.05639</td>\n",
       "      <td>0.065092</td>\n",
       "      <td>0.128428</td>\n",
       "      <td>0.095475</td>\n",
       "      <td>0.112714</td>\n",
       "      <td>0.058082</td>\n",
       "      <td>0.185391</td>\n",
       "      <td>0.365896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-9.905914e-01</td>\n",
       "      <td>-1.636898e+00</td>\n",
       "      <td>-7.355743e-01</td>\n",
       "      <td>-6.474524e-01</td>\n",
       "      <td>-4.620329e-01</td>\n",
       "      <td>-4.647157e-01</td>\n",
       "      <td>-0.021685</td>\n",
       "      <td>-4.391711e-02</td>\n",
       "      <td>-1.086872e-01</td>\n",
       "      <td>-3.303316e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-9.905914e-01</td>\n",
       "      <td>-9.067708e-01</td>\n",
       "      <td>-7.355743e-01</td>\n",
       "      <td>-6.474524e-01</td>\n",
       "      <td>-4.620329e-01</td>\n",
       "      <td>-4.647157e-01</td>\n",
       "      <td>-0.021685</td>\n",
       "      <td>-4.391711e-02</td>\n",
       "      <td>-1.086872e-01</td>\n",
       "      <td>-3.303316e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-4.948532e-01</td>\n",
       "      <td>-1.766434e-01</td>\n",
       "      <td>-7.355743e-01</td>\n",
       "      <td>-6.474524e-01</td>\n",
       "      <td>-4.620329e-01</td>\n",
       "      <td>-4.647157e-01</td>\n",
       "      <td>-0.021685</td>\n",
       "      <td>-4.391711e-02</td>\n",
       "      <td>-1.086872e-01</td>\n",
       "      <td>-3.303316e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.966230e-01</td>\n",
       "      <td>9.185477e-01</td>\n",
       "      <td>1.359482e+00</td>\n",
       "      <td>1.544515e+00</td>\n",
       "      <td>-4.620329e-01</td>\n",
       "      <td>-4.647157e-01</td>\n",
       "      <td>-0.021685</td>\n",
       "      <td>-4.391711e-02</td>\n",
       "      <td>-1.086872e-01</td>\n",
       "      <td>-3.303316e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.479576e+00</td>\n",
       "      <td>2.378802e+00</td>\n",
       "      <td>1.359482e+00</td>\n",
       "      <td>1.544515e+00</td>\n",
       "      <td>2.164348e+00</td>\n",
       "      <td>2.151853e+00</td>\n",
       "      <td>46.115719</td>\n",
       "      <td>2.277017e+01</td>\n",
       "      <td>9.200712e+00</td>\n",
       "      <td>3.027261e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 212 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ps_ind_01     ps_ind_03  ps_ind_06_bin  ps_ind_07_bin  \\\n",
       "count  2.000000e+05  2.000000e+05   2.000000e+05   2.000000e+05   \n",
       "mean  -4.661160e-17  1.601563e-16  -4.462208e-17   4.348522e-17   \n",
       "std    1.000003e+00  1.000003e+00   1.000003e+00   1.000003e+00   \n",
       "min   -9.905914e-01 -1.636898e+00  -7.355743e-01  -6.474524e-01   \n",
       "25%   -9.905914e-01 -9.067708e-01  -7.355743e-01  -6.474524e-01   \n",
       "50%   -4.948532e-01 -1.766434e-01  -7.355743e-01  -6.474524e-01   \n",
       "75%    4.966230e-01  9.185477e-01   1.359482e+00   1.544515e+00   \n",
       "max    2.479576e+00  2.378802e+00   1.359482e+00   1.544515e+00   \n",
       "\n",
       "       ps_ind_08_bin  ps_ind_09_bin  ps_ind_10_bin  ps_ind_11_bin  \\\n",
       "count   2.000000e+05   2.000000e+05  200000.000000   2.000000e+05   \n",
       "mean    6.785683e-17  -1.007550e-16       0.000000   2.046363e-17   \n",
       "std     1.000003e+00   1.000003e+00       1.000003   1.000003e+00   \n",
       "min    -4.620329e-01  -4.647157e-01      -0.021685  -4.391711e-02   \n",
       "25%    -4.620329e-01  -4.647157e-01      -0.021685  -4.391711e-02   \n",
       "50%    -4.620329e-01  -4.647157e-01      -0.021685  -4.391711e-02   \n",
       "75%    -4.620329e-01  -4.647157e-01      -0.021685  -4.391711e-02   \n",
       "max     2.164348e+00   2.151853e+00      46.115719   2.277017e+01   \n",
       "\n",
       "       ps_ind_12_bin  ps_ind_13_bin  ...  ps_car_11_cat_0.9698844814339967  \\\n",
       "count   2.000000e+05   2.000000e+05  ...                     200000.000000   \n",
       "mean   -4.220624e-17  -6.252776e-18  ...                          0.005090   \n",
       "std     1.000003e+00   1.000003e+00  ...                          0.071163   \n",
       "min    -1.086872e-01  -3.303316e-02  ...                          0.000000   \n",
       "25%    -1.086872e-01  -3.303316e-02  ...                          0.000000   \n",
       "50%    -1.086872e-01  -3.303316e-02  ...                          0.000000   \n",
       "75%    -1.086872e-01  -3.303316e-02  ...                          0.000000   \n",
       "max     9.200712e+00   3.027261e+01  ...                          1.000000   \n",
       "\n",
       "       ps_car_11_cat_0.9999078260160954  ps_car_11_cat_1.0299311705981942  \\\n",
       "count                     200000.000000                      200000.00000   \n",
       "mean                           0.003105                           0.00319   \n",
       "std                            0.055636                           0.05639   \n",
       "min                            0.000000                           0.00000   \n",
       "25%                            0.000000                           0.00000   \n",
       "50%                            0.000000                           0.00000   \n",
       "75%                            0.000000                           0.00000   \n",
       "max                            1.000000                           1.00000   \n",
       "\n",
       "       ps_car_11_cat_1.0599545151802927  ps_car_11_cat_1.0899778597623915  \\\n",
       "count                     200000.000000                     200000.000000   \n",
       "mean                           0.004255                          0.016775   \n",
       "std                            0.065092                          0.128428   \n",
       "min                            0.000000                          0.000000   \n",
       "25%                            0.000000                          0.000000   \n",
       "50%                            0.000000                          0.000000   \n",
       "75%                            0.000000                          0.000000   \n",
       "max                            1.000000                          1.000000   \n",
       "\n",
       "       ps_car_11_cat_1.1200012043444902  ps_car_11_cat_1.1500245489265888  \\\n",
       "count                     200000.000000                     200000.000000   \n",
       "mean                           0.009200                          0.012870   \n",
       "std                            0.095475                          0.112714   \n",
       "min                            0.000000                          0.000000   \n",
       "25%                            0.000000                          0.000000   \n",
       "50%                            0.000000                          0.000000   \n",
       "75%                            0.000000                          0.000000   \n",
       "max                            1.000000                          1.000000   \n",
       "\n",
       "       ps_car_11_cat_1.1800478935086876  ps_car_11_cat_1.210071238090786  \\\n",
       "count                     200000.000000                    200000.000000   \n",
       "mean                           0.003385                         0.035640   \n",
       "std                            0.058082                         0.185391   \n",
       "min                            0.000000                         0.000000   \n",
       "25%                            0.000000                         0.000000   \n",
       "50%                            0.000000                         0.000000   \n",
       "75%                            0.000000                         0.000000   \n",
       "max                            1.000000                         1.000000   \n",
       "\n",
       "       ps_car_11_cat_1.2400945826728849  \n",
       "count                     200000.000000  \n",
       "mean                           0.159235  \n",
       "std                            0.365896  \n",
       "min                            0.000000  \n",
       "25%                            0.000000  \n",
       "50%                            0.000000  \n",
       "75%                            0.000000  \n",
       "max                            1.000000  \n",
       "\n",
       "[8 rows x 212 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "cat_columns = [col for col in normalized_data.columns if col.endswith('_cat')]\n",
    "\n",
    "one_hot_encoder = OneHotEncoder(sparse_output=False, drop=\"first\")\n",
    "one_hot_encoded = one_hot_encoder.fit_transform(normalized_data[cat_columns])\n",
    "\n",
    "data_encoded = normalized_data.drop(cat_columns, axis=1)\n",
    "one_hot_df = pd.DataFrame(one_hot_encoded, columns=one_hot_encoder.get_feature_names_out(cat_columns))\n",
    "\n",
    "data_encoded.reset_index(drop=True, inplace=True)\n",
    "data_encoded = pd.concat([data_encoded, one_hot_df], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(normalize(data_encoded), target, test_size=0.5)\n",
    "data_encoded.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5959\n",
      "Precision: 0.6026\n",
      "Recall: 0.5633\n",
      "F1: 0.5823\n"
     ]
    }
   ],
   "source": [
    "display_metrics(evaluate_model(X_train, y_train, X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "izITXcOWaRLW"
   },
   "source": [
    "Как можно было заменить, one-hot-кодирование может сильно увеличивать количество признаков в датасете, что сказывается на памяти, особенно, если некоторый признак имеет большое количество значений. Эту проблему решает другой способ кодирование категориальных признаков — счётчики. Основная идея в том, что нам важны не сами категории, а значения целевой переменной, которые имеют объекты этой категории. Каждый категориальный признак мы заменим средним значением целевой переменной по всем объектам этой же категории:\n",
    "$$\n",
    "g_j(x, X) = \\frac{\\sum_{i=1}^{l} [f_j(x) = f_j(x_i)][y_i = +1]}{\\sum_{i=1}^{l} [f_j(x) = f_j(x_i)]}\n",
    "$$\n",
    "\n",
    "__Задание 2.__ Закодируйте категориальные переменные с помощью счётчиков (ровно так, как описано выше без каких-либо хитростей). Обучите логистическую регрессию и посмотрите на качество модели на тестовом множестве. Сравните время обучения с предыдущим экспериментов. Заметили ли вы что-то интересное?\n",
    "\n",
    "__(2 балла)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "vJmhJjcyaRLW"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Егор\\AppData\\Local\\Temp\\ipykernel_6204\\3777042462.py:10: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  CTR_data[column][data[column] == val] = np.mean(target[data[column] == val])\n",
      "C:\\Users\\Егор\\AppData\\Local\\Temp\\ipykernel_6204\\3777042462.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  CTR_data[column][data[column] == val] = np.mean(target[data[column] == val])\n",
      "C:\\Users\\Егор\\AppData\\Local\\Temp\\ipykernel_6204\\3777042462.py:10: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.9112149532710281' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  CTR_data[column][data[column] == val] = np.mean(target[data[column] == val])\n",
      "C:\\Users\\Егор\\AppData\\Local\\Temp\\ipykernel_6204\\3777042462.py:10: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  CTR_data[column][data[column] == val] = np.mean(target[data[column] == val])\n",
      "C:\\Users\\Егор\\AppData\\Local\\Temp\\ipykernel_6204\\3777042462.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  CTR_data[column][data[column] == val] = np.mean(target[data[column] == val])\n",
      "C:\\Users\\Егор\\AppData\\Local\\Temp\\ipykernel_6204\\3777042462.py:10: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.9640718562874252' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  CTR_data[column][data[column] == val] = np.mean(target[data[column] == val])\n",
      "C:\\Users\\Егор\\AppData\\Local\\Temp\\ipykernel_6204\\3777042462.py:10: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  CTR_data[column][data[column] == val] = np.mean(target[data[column] == val])\n",
      "C:\\Users\\Егор\\AppData\\Local\\Temp\\ipykernel_6204\\3777042462.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  CTR_data[column][data[column] == val] = np.mean(target[data[column] == val])\n",
      "C:\\Users\\Егор\\AppData\\Local\\Temp\\ipykernel_6204\\3777042462.py:10: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.6974228444161629' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  CTR_data[column][data[column] == val] = np.mean(target[data[column] == val])\n",
      "C:\\Users\\Егор\\AppData\\Local\\Temp\\ipykernel_6204\\3777042462.py:10: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  CTR_data[column][data[column] == val] = np.mean(target[data[column] == val])\n",
      "C:\\Users\\Егор\\AppData\\Local\\Temp\\ipykernel_6204\\3777042462.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  CTR_data[column][data[column] == val] = np.mean(target[data[column] == val])\n",
      "C:\\Users\\Егор\\AppData\\Local\\Temp\\ipykernel_6204\\3777042462.py:10: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.9651162790697675' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  CTR_data[column][data[column] == val] = np.mean(target[data[column] == val])\n",
      "C:\\Users\\Егор\\AppData\\Local\\Temp\\ipykernel_6204\\3777042462.py:10: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  CTR_data[column][data[column] == val] = np.mean(target[data[column] == val])\n",
      "C:\\Users\\Егор\\AppData\\Local\\Temp\\ipykernel_6204\\3777042462.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  CTR_data[column][data[column] == val] = np.mean(target[data[column] == val])\n",
      "C:\\Users\\Егор\\AppData\\Local\\Temp\\ipykernel_6204\\3777042462.py:10: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.5804807355954226' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  CTR_data[column][data[column] == val] = np.mean(target[data[column] == val])\n",
      "C:\\Users\\Егор\\AppData\\Local\\Temp\\ipykernel_6204\\3777042462.py:10: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  CTR_data[column][data[column] == val] = np.mean(target[data[column] == val])\n",
      "C:\\Users\\Егор\\AppData\\Local\\Temp\\ipykernel_6204\\3777042462.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  CTR_data[column][data[column] == val] = np.mean(target[data[column] == val])\n",
      "C:\\Users\\Егор\\AppData\\Local\\Temp\\ipykernel_6204\\3777042462.py:10: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.4715437215876533' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  CTR_data[column][data[column] == val] = np.mean(target[data[column] == val])\n",
      "C:\\Users\\Егор\\AppData\\Local\\Temp\\ipykernel_6204\\3777042462.py:10: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  CTR_data[column][data[column] == val] = np.mean(target[data[column] == val])\n",
      "C:\\Users\\Егор\\AppData\\Local\\Temp\\ipykernel_6204\\3777042462.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  CTR_data[column][data[column] == val] = np.mean(target[data[column] == val])\n",
      "C:\\Users\\Егор\\AppData\\Local\\Temp\\ipykernel_6204\\3777042462.py:10: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.4775618595351162' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  CTR_data[column][data[column] == val] = np.mean(target[data[column] == val])\n",
      "C:\\Users\\Егор\\AppData\\Local\\Temp\\ipykernel_6204\\3777042462.py:10: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  CTR_data[column][data[column] == val] = np.mean(target[data[column] == val])\n",
      "C:\\Users\\Егор\\AppData\\Local\\Temp\\ipykernel_6204\\3777042462.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  CTR_data[column][data[column] == val] = np.mean(target[data[column] == val])\n",
      "C:\\Users\\Егор\\AppData\\Local\\Temp\\ipykernel_6204\\3777042462.py:10: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.46357948632062496' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  CTR_data[column][data[column] == val] = np.mean(target[data[column] == val])\n",
      "C:\\Users\\Егор\\AppData\\Local\\Temp\\ipykernel_6204\\3777042462.py:10: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  CTR_data[column][data[column] == val] = np.mean(target[data[column] == val])\n",
      "C:\\Users\\Егор\\AppData\\Local\\Temp\\ipykernel_6204\\3777042462.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  CTR_data[column][data[column] == val] = np.mean(target[data[column] == val])\n",
      "C:\\Users\\Егор\\AppData\\Local\\Temp\\ipykernel_6204\\3777042462.py:10: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.4740934096777815' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  CTR_data[column][data[column] == val] = np.mean(target[data[column] == val])\n",
      "C:\\Users\\Егор\\AppData\\Local\\Temp\\ipykernel_6204\\3777042462.py:10: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  CTR_data[column][data[column] == val] = np.mean(target[data[column] == val])\n",
      "C:\\Users\\Егор\\AppData\\Local\\Temp\\ipykernel_6204\\3777042462.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  CTR_data[column][data[column] == val] = np.mean(target[data[column] == val])\n",
      "C:\\Users\\Егор\\AppData\\Local\\Temp\\ipykernel_6204\\3777042462.py:10: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.6887755102040817' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  CTR_data[column][data[column] == val] = np.mean(target[data[column] == val])\n",
      "C:\\Users\\Егор\\AppData\\Local\\Temp\\ipykernel_6204\\3777042462.py:10: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  CTR_data[column][data[column] == val] = np.mean(target[data[column] == val])\n",
      "C:\\Users\\Егор\\AppData\\Local\\Temp\\ipykernel_6204\\3777042462.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  CTR_data[column][data[column] == val] = np.mean(target[data[column] == val])\n",
      "C:\\Users\\Егор\\AppData\\Local\\Temp\\ipykernel_6204\\3777042462.py:10: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.5532119914346895' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  CTR_data[column][data[column] == val] = np.mean(target[data[column] == val])\n",
      "C:\\Users\\Егор\\AppData\\Local\\Temp\\ipykernel_6204\\3777042462.py:10: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  CTR_data[column][data[column] == val] = np.mean(target[data[column] == val])\n",
      "C:\\Users\\Егор\\AppData\\Local\\Temp\\ipykernel_6204\\3777042462.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  CTR_data[column][data[column] == val] = np.mean(target[data[column] == val])\n",
      "C:\\Users\\Егор\\AppData\\Local\\Temp\\ipykernel_6204\\3777042462.py:10: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.7553516819571865' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  CTR_data[column][data[column] == val] = np.mean(target[data[column] == val])\n",
      "C:\\Users\\Егор\\AppData\\Local\\Temp\\ipykernel_6204\\3777042462.py:10: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  CTR_data[column][data[column] == val] = np.mean(target[data[column] == val])\n",
      "C:\\Users\\Егор\\AppData\\Local\\Temp\\ipykernel_6204\\3777042462.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  CTR_data[column][data[column] == val] = np.mean(target[data[column] == val])\n",
      "C:\\Users\\Егор\\AppData\\Local\\Temp\\ipykernel_6204\\3777042462.py:10: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.4834063869755792' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  CTR_data[column][data[column] == val] = np.mean(target[data[column] == val])\n",
      "C:\\Users\\Егор\\AppData\\Local\\Temp\\ipykernel_6204\\3777042462.py:10: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  CTR_data[column][data[column] == val] = np.mean(target[data[column] == val])\n",
      "C:\\Users\\Егор\\AppData\\Local\\Temp\\ipykernel_6204\\3777042462.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  CTR_data[column][data[column] == val] = np.mean(target[data[column] == val])\n",
      "C:\\Users\\Егор\\AppData\\Local\\Temp\\ipykernel_6204\\3777042462.py:10: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.5318979266347688' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  CTR_data[column][data[column] == val] = np.mean(target[data[column] == val])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ps_ind_01</th>\n",
       "      <th>ps_ind_02_cat</th>\n",
       "      <th>ps_ind_03</th>\n",
       "      <th>ps_ind_04_cat</th>\n",
       "      <th>ps_ind_05_cat</th>\n",
       "      <th>ps_ind_06_bin</th>\n",
       "      <th>ps_ind_07_bin</th>\n",
       "      <th>ps_ind_08_bin</th>\n",
       "      <th>ps_ind_09_bin</th>\n",
       "      <th>ps_ind_10_bin</th>\n",
       "      <th>...</th>\n",
       "      <th>ps_calc_11</th>\n",
       "      <th>ps_calc_12</th>\n",
       "      <th>ps_calc_13</th>\n",
       "      <th>ps_calc_14</th>\n",
       "      <th>ps_calc_15_bin</th>\n",
       "      <th>ps_calc_16_bin</th>\n",
       "      <th>ps_calc_17_bin</th>\n",
       "      <th>ps_calc_18_bin</th>\n",
       "      <th>ps_calc_19_bin</th>\n",
       "      <th>ps_calc_20_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.998215</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>4.483870</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.351100</td>\n",
       "      <td>0.295375</td>\n",
       "      <td>0.175920</td>\n",
       "      <td>0.177605</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>...</td>\n",
       "      <td>5.443865</td>\n",
       "      <td>1.443745</td>\n",
       "      <td>2.873590</td>\n",
       "      <td>7.544455</td>\n",
       "      <td>0.123355</td>\n",
       "      <td>0.630875</td>\n",
       "      <td>0.553405</td>\n",
       "      <td>0.287530</td>\n",
       "      <td>0.345000</td>\n",
       "      <td>0.152800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.017199</td>\n",
       "      <td>0.015959</td>\n",
       "      <td>2.739255</td>\n",
       "      <td>0.020419</td>\n",
       "      <td>0.050252</td>\n",
       "      <td>0.477315</td>\n",
       "      <td>0.456212</td>\n",
       "      <td>0.380753</td>\n",
       "      <td>0.382181</td>\n",
       "      <td>0.021674</td>\n",
       "      <td>...</td>\n",
       "      <td>2.342462</td>\n",
       "      <td>1.201163</td>\n",
       "      <td>1.692875</td>\n",
       "      <td>2.745287</td>\n",
       "      <td>0.328845</td>\n",
       "      <td>0.482569</td>\n",
       "      <td>0.497141</td>\n",
       "      <td>0.452612</td>\n",
       "      <td>0.475369</td>\n",
       "      <td>0.359796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.494915</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.486218</td>\n",
       "      <td>0.480547</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.494915</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.486218</td>\n",
       "      <td>0.480547</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.494915</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.486218</td>\n",
       "      <td>0.480547</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.500783</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.517318</td>\n",
       "      <td>0.480547</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.911215</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.964072</td>\n",
       "      <td>0.697423</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ps_ind_01  ps_ind_02_cat      ps_ind_03  ps_ind_04_cat  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean        1.998215       0.500000       4.483870       0.500000   \n",
       "std         2.017199       0.015959       2.739255       0.020419   \n",
       "min         0.000000       0.494915       0.000000       0.486218   \n",
       "25%         0.000000       0.494915       2.000000       0.486218   \n",
       "50%         1.000000       0.494915       4.000000       0.486218   \n",
       "75%         3.000000       0.500783       7.000000       0.517318   \n",
       "max         7.000000       0.911215      11.000000       0.964072   \n",
       "\n",
       "       ps_ind_05_cat  ps_ind_06_bin  ps_ind_07_bin  ps_ind_08_bin  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean        0.500000       0.351100       0.295375       0.175920   \n",
       "std         0.050252       0.477315       0.456212       0.380753   \n",
       "min         0.480547       0.000000       0.000000       0.000000   \n",
       "25%         0.480547       0.000000       0.000000       0.000000   \n",
       "50%         0.480547       0.000000       0.000000       0.000000   \n",
       "75%         0.480547       1.000000       1.000000       0.000000   \n",
       "max         0.697423       1.000000       1.000000       1.000000   \n",
       "\n",
       "       ps_ind_09_bin  ps_ind_10_bin  ...     ps_calc_11     ps_calc_12  \\\n",
       "count  200000.000000  200000.000000  ...  200000.000000  200000.000000   \n",
       "mean        0.177605       0.000470  ...       5.443865       1.443745   \n",
       "std         0.382181       0.021674  ...       2.342462       1.201163   \n",
       "min         0.000000       0.000000  ...       0.000000       0.000000   \n",
       "25%         0.000000       0.000000  ...       4.000000       1.000000   \n",
       "50%         0.000000       0.000000  ...       5.000000       1.000000   \n",
       "75%         0.000000       0.000000  ...       7.000000       2.000000   \n",
       "max         1.000000       1.000000  ...      18.000000       8.000000   \n",
       "\n",
       "          ps_calc_13     ps_calc_14  ps_calc_15_bin  ps_calc_16_bin  \\\n",
       "count  200000.000000  200000.000000   200000.000000   200000.000000   \n",
       "mean        2.873590       7.544455        0.123355        0.630875   \n",
       "std         1.692875       2.745287        0.328845        0.482569   \n",
       "min         0.000000       0.000000        0.000000        0.000000   \n",
       "25%         2.000000       6.000000        0.000000        0.000000   \n",
       "50%         3.000000       7.000000        0.000000        1.000000   \n",
       "75%         4.000000       9.000000        0.000000        1.000000   \n",
       "max        13.000000      22.000000        1.000000        1.000000   \n",
       "\n",
       "       ps_calc_17_bin  ps_calc_18_bin  ps_calc_19_bin  ps_calc_20_bin  \n",
       "count   200000.000000   200000.000000   200000.000000   200000.000000  \n",
       "mean         0.553405        0.287530        0.345000        0.152800  \n",
       "std          0.497141        0.452612        0.475369        0.359796  \n",
       "min          0.000000        0.000000        0.000000        0.000000  \n",
       "25%          0.000000        0.000000        0.000000        0.000000  \n",
       "50%          1.000000        0.000000        0.000000        0.000000  \n",
       "75%          1.000000        1.000000        1.000000        0.000000  \n",
       "max          1.000000        1.000000        1.000000        1.000000  \n",
       "\n",
       "[8 rows x 57 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CTR_data = data.copy()\n",
    "\n",
    "cat_columns = []\n",
    "\n",
    "for column in data:\n",
    "    if \"cat\" in column:\n",
    "        cat_columns.append(column)\n",
    "        unique_vals = np.unique(data[column])\n",
    "        for val in unique_vals:\n",
    "            CTR_data[column][data[column] == val] = np.mean(target[data[column] == val])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(normalize(CTR_data), target, test_size=0.5)\n",
    "CTR_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5945\n",
      "Precision: 0.5978\n",
      "Recall: 0.5733\n",
      "F1: 0.5853\n"
     ]
    }
   ],
   "source": [
    "display_metrics(evaluate_model(X_train, y_train, X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CZ6BybtVaRLW"
   },
   "source": [
    "__Вывод:__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество\n",
    "Качество между моделью обученной с использованием счетчиков (CTR) и OneHotEncoding не так сильно различается. Значения упали всего на ~0.15-0.3%, что не является критическим.\n",
    "\n",
    "Время обучения\n",
    "Время в свою очередь сильно изменилось. С целых 2 секунд до жалких 0.3 секунд. Время улучшилось в 6 раз\n",
    "\n",
    "Итог\n",
    "По сравнению с выигрышем времени проигрыш в точности никчемен, поэтому CTR показывает свое превосходство в данном случае над OneHotEncoding\n",
    "\n",
    "Отметим, что такие признаки сами по себе являются классификаторами и, обучаясь на них, мы допускаем \"утечку\" целевой переменной в признаки. Это ведёт к переобучению, поэтому считать такие признаки необходимо таким образом, чтобы при вычислении для конкретного объекта его целевая метка не использовалась. Это можно делать следующими способами:\n",
    "\n",
    "вычислять значение счётчика по всем объектам расположенным выше в датасете (например, если у нас выборка отсортирована по времени)\n",
    "вычислять по фолдам, то есть делить выборку на некоторое количество частей и подсчитывать значение признаков по всем фолдам кроме текущего (как делается в кросс-валидации)\n",
    "внесение некоторого шума в посчитанные признаки (необходимо соблюсти баланс между избавление от переобучения и полезностью признаков)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IUSCGlbhaRLW"
   },
   "source": [
    "Отметим, что такие признаки сами по себе являются классификаторами и, обучаясь на них, мы допускаем \"утечку\" целевой переменной в признаки. Это ведёт к переобучению, поэтому считать такие признаки необходимо таким образом, чтобы при вычислении для конкретного объекта его целевая метка не использовалась. Это можно делать следующими способами:\n",
    "- вычислять значение счётчика по всем объектам расположенным выше в датасете (например, если у нас выборка отсортирована по времени)\n",
    "- вычислять по фолдам, то есть делить выборку на некоторое количество частей и подсчитывать значение признаков по всем фолдам кроме текущего (как делается в кросс-валидации)\n",
    "- внесение некоторого шума в посчитанные признаки (необходимо соблюсти баланс между избавление от переобучения и полезностью признаков).\n",
    "\n",
    "__Задание 3.__ Реализуйте корректное вычисление счётчиков двумя из трех вышеперчисленных способов, сравните. Снова обучите логистическую регрессию, оцените качество. Сделайте выводы.\n",
    "\n",
    "__(3 балла)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "YX9gBIEJaRLW"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Егор\\AppData\\Local\\Temp\\ipykernel_6204\\1194169326.py:7: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  CTR_noise_data[col][data[col] == val] = np.mean(target_vals) + np.random.random(target_vals.shape) * 0.02\n",
      "C:\\Users\\Егор\\AppData\\Local\\Temp\\ipykernel_6204\\1194169326.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  CTR_noise_data[col][data[col] == val] = np.mean(target_vals) + np.random.random(target_vals.shape) * 0.02\n",
      "C:\\Users\\Егор\\AppData\\Local\\Temp\\ipykernel_6204\\1194169326.py:7: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[0.92484899 0.92701133 0.92766654 0.91621416 0.92773649 0.92207676\n",
      " 0.91324632 0.929553   0.9301723  0.91143968 0.91976152 0.92425219\n",
      " 0.92689607 0.92888623 0.92150616 0.9301714  0.93020949 0.92172183\n",
      " 0.92870635 0.91237527 0.92318329 0.91882841 0.91986513 0.91522913\n",
      " 0.91173022 0.9127339  0.92357634 0.92800432 0.91331141 0.93061853\n",
      " 0.92149037 0.91983714 0.91890556 0.91155862 0.91325792 0.92881873\n",
      " 0.92650402 0.91138849 0.92517728 0.92293901 0.91574364 0.91331014\n",
      " 0.92949406 0.92481393 0.91871029 0.91449985 0.92223007 0.91439606\n",
      " 0.91651938 0.91865231 0.92826067 0.92519232 0.91169667 0.91697767\n",
      " 0.92542634 0.92998984 0.91765865 0.92143756 0.92947811 0.91454489\n",
      " 0.92250204 0.91660466 0.91445594 0.91875884 0.91889603 0.91684346\n",
      " 0.92250429 0.92718955 0.92126342 0.92122731 0.9186615  0.92449957\n",
      " 0.92064079 0.9284146  0.91687806 0.92389685 0.9176157  0.91332128\n",
      " 0.91216974 0.91553754 0.92772034 0.92639984 0.92643731 0.92089707\n",
      " 0.92667185 0.92478015 0.92570707 0.9172852  0.92934673 0.91769493\n",
      " 0.91794944 0.91703008 0.91154287 0.91931196 0.92488915 0.91616328\n",
      " 0.92903148 0.92553755 0.92690389 0.92989238 0.92614032 0.91640902\n",
      " 0.91534262 0.91320115 0.93061296 0.92733317 0.92803292 0.92764214\n",
      " 0.92747868 0.91165837 0.92939816 0.92503904 0.91123992 0.92529822\n",
      " 0.92937926 0.92131222 0.91897506 0.92429926 0.91590279 0.9281122\n",
      " 0.93073069 0.92952396 0.92584333 0.91817024 0.92845007 0.92575073\n",
      " 0.92390558 0.91151659 0.9234302  0.9216793  0.91566543 0.91350857\n",
      " 0.92289753 0.9247307  0.91230273 0.92769472 0.92238404 0.92600771\n",
      " 0.91363111 0.92039427 0.91866853 0.9197777  0.92835676 0.91570701\n",
      " 0.93103621 0.92200815 0.91307668 0.92751884 0.93085229 0.92513221\n",
      " 0.91998005 0.91562468 0.92382778 0.91677151 0.92854361 0.91176512\n",
      " 0.91178672 0.91784844 0.92216031 0.91737233 0.93034658 0.92919225\n",
      " 0.92594075 0.92471602 0.92777996 0.92216201 0.92309389 0.91929172\n",
      " 0.91907515 0.92122264 0.92102568 0.93040867 0.92229689 0.91775256\n",
      " 0.91827892 0.92986513 0.91316407 0.92461874 0.92097062 0.9131321\n",
      " 0.92330309 0.92317071 0.92988705 0.93009126 0.91384079 0.92623715\n",
      " 0.92466764 0.92302166 0.92682167 0.91950017 0.92923179 0.92599259\n",
      " 0.91427199 0.91695038 0.91697428 0.92160839 0.92057301 0.9203336\n",
      " 0.91767794 0.92632495 0.92308878 0.92331578 0.92039856 0.92798063\n",
      " 0.91389578 0.92647125 0.92959288 0.92906275 0.91410352 0.92186251\n",
      " 0.92133914 0.9309529  0.93034848 0.91944484]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  CTR_noise_data[col][data[col] == val] = np.mean(target_vals) + np.random.random(target_vals.shape) * 0.02\n",
      "C:\\Users\\Егор\\AppData\\Local\\Temp\\ipykernel_6204\\1194169326.py:7: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  CTR_noise_data[col][data[col] == val] = np.mean(target_vals) + np.random.random(target_vals.shape) * 0.02\n",
      "C:\\Users\\Егор\\AppData\\Local\\Temp\\ipykernel_6204\\1194169326.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  CTR_noise_data[col][data[col] == val] = np.mean(target_vals) + np.random.random(target_vals.shape) * 0.02\n",
      "C:\\Users\\Егор\\AppData\\Local\\Temp\\ipykernel_6204\\1194169326.py:7: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[0.96687485 0.96805874 0.97520941 0.9768591  0.97941873 0.96915344\n",
      " 0.97761496 0.97951086 0.97304756 0.96515111 0.97152844 0.97079709\n",
      " 0.97936185 0.98407126 0.97692052 0.97722009 0.97613079 0.97592946\n",
      " 0.97697858 0.97245128 0.97275902 0.97123136 0.97009835 0.96719056\n",
      " 0.96523908 0.96475865 0.98017758 0.9753672  0.97406152 0.96950777\n",
      " 0.96931288 0.9777264  0.97360367 0.96658589 0.96543061 0.97423827\n",
      " 0.96780373 0.98132404 0.97392257 0.98068161 0.96809148 0.9750387\n",
      " 0.9709124  0.9803583  0.96690324 0.96832918 0.98346586 0.98361136\n",
      " 0.97446777 0.96827438 0.98281683 0.96539883 0.98154008 0.97845684\n",
      " 0.9838633  0.96982051 0.96732508 0.97313147 0.98232853 0.9809778\n",
      " 0.97798085 0.96832678 0.96784579 0.97791927 0.98013292 0.97175066\n",
      " 0.97161483 0.98128039 0.96437643 0.98085981 0.98229786 0.96940049\n",
      " 0.98172081 0.96607201 0.97932161 0.96407583 0.97301394 0.98210362\n",
      " 0.97594215 0.97471839 0.97644125 0.96450078 0.96889379 0.98387354\n",
      " 0.96771142 0.98105152 0.97023113 0.97600018 0.96576258 0.97576468\n",
      " 0.96605081 0.98024876 0.98077846 0.96425948 0.97132501 0.98337255\n",
      " 0.98077322 0.97176402 0.97162014 0.96880905 0.97473331 0.98276589\n",
      " 0.9766913  0.97494951 0.97811924 0.9666753  0.98008712 0.97266634\n",
      " 0.97474394 0.97333941 0.97032641 0.96933503 0.96698197 0.97235557\n",
      " 0.96649234 0.96806225 0.97387491 0.9656505  0.97902811 0.9822945\n",
      " 0.97225153 0.97892411 0.97449091 0.97148178 0.98354736 0.96467975\n",
      " 0.97454344 0.97285676 0.97982505 0.96492431 0.97365079 0.96629192\n",
      " 0.97546992 0.97438984 0.97860252 0.97380907 0.97306802 0.98055664\n",
      " 0.96685881 0.97015179 0.96581936 0.97633009 0.96799831 0.97773364\n",
      " 0.98331048 0.97241933 0.9674141  0.97970349 0.97471688 0.96879319\n",
      " 0.97071754 0.96436816 0.97954403 0.98359048 0.96488192 0.98031518\n",
      " 0.98296642 0.96657951 0.97004783 0.98133021 0.97773088 0.96584669\n",
      " 0.97917578 0.96475917 0.96801748 0.9819097  0.97460487]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  CTR_noise_data[col][data[col] == val] = np.mean(target_vals) + np.random.random(target_vals.shape) * 0.02\n",
      "C:\\Users\\Егор\\AppData\\Local\\Temp\\ipykernel_6204\\1194169326.py:7: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  CTR_noise_data[col][data[col] == val] = np.mean(target_vals) + np.random.random(target_vals.shape) * 0.02\n",
      "C:\\Users\\Егор\\AppData\\Local\\Temp\\ipykernel_6204\\1194169326.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  CTR_noise_data[col][data[col] == val] = np.mean(target_vals) + np.random.random(target_vals.shape) * 0.02\n",
      "C:\\Users\\Егор\\AppData\\Local\\Temp\\ipykernel_6204\\1194169326.py:7: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[0.71523896 0.70593247 0.71017615 ... 0.70709402 0.70803086 0.70498971]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  CTR_noise_data[col][data[col] == val] = np.mean(target_vals) + np.random.random(target_vals.shape) * 0.02\n",
      "C:\\Users\\Егор\\AppData\\Local\\Temp\\ipykernel_6204\\1194169326.py:7: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  CTR_noise_data[col][data[col] == val] = np.mean(target_vals) + np.random.random(target_vals.shape) * 0.02\n",
      "C:\\Users\\Егор\\AppData\\Local\\Temp\\ipykernel_6204\\1194169326.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  CTR_noise_data[col][data[col] == val] = np.mean(target_vals) + np.random.random(target_vals.shape) * 0.02\n",
      "C:\\Users\\Егор\\AppData\\Local\\Temp\\ipykernel_6204\\1194169326.py:7: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[0.9717576  0.98099993 0.97456745 0.98237726 0.98496065 0.97472892\n",
      " 0.97672215 0.97751486 0.97706436 0.98163979 0.97573366 0.9806578\n",
      " 0.98371693 0.96983597 0.96544564 0.98036186 0.97697774 0.97051048\n",
      " 0.96714246 0.97617119 0.97571436 0.9795099  0.97172646 0.9671593\n",
      " 0.97029939 0.97462868 0.97972478 0.97200805 0.97396805 0.97992889\n",
      " 0.97163436 0.97275484 0.98278906 0.97130494 0.97289586 0.98286198\n",
      " 0.98499546 0.97788297 0.98213599 0.98510717 0.97584752 0.97760038\n",
      " 0.98480593 0.97043224 0.98357749 0.97954971 0.96618796 0.97566096\n",
      " 0.96911902 0.98022611 0.97340663 0.97344454 0.98036223 0.97318713\n",
      " 0.98367419 0.97601408 0.97063303 0.9740696  0.97067947 0.97944362\n",
      " 0.96610463 0.96568835 0.97756173 0.97138849 0.96810513 0.97048091\n",
      " 0.96989811 0.98058924 0.97957007 0.98131788 0.98277136 0.98142838\n",
      " 0.96820014 0.98222171 0.97106201 0.96950773 0.97288451 0.9758151\n",
      " 0.98402341 0.97599658 0.97575528 0.97081158 0.96781805 0.96770444\n",
      " 0.97146533 0.98059855 0.96629386 0.97027516 0.96681303 0.98344564\n",
      " 0.96789074 0.9819519  0.9832468  0.97213125 0.98019808 0.98281826\n",
      " 0.98399792 0.98198387 0.97526018 0.98055278 0.97680945 0.96898479\n",
      " 0.97927238 0.96913168 0.98318442 0.96702193 0.98365327 0.98442663\n",
      " 0.96633857 0.98352401 0.98182461 0.97827131 0.96573253 0.97418295\n",
      " 0.97628328 0.9789152  0.96977491 0.97517932 0.96952643 0.98074214\n",
      " 0.98468677 0.97272249 0.9836922  0.96588581 0.96945997 0.9693071\n",
      " 0.97722816 0.97755486 0.97934286 0.9815335  0.96532959 0.97651131\n",
      " 0.97574203 0.96693318 0.98089189 0.97846341 0.97282367 0.97280945\n",
      " 0.97603572 0.98145679 0.98290671 0.97959832 0.98359374 0.98453996\n",
      " 0.97395203 0.98114957 0.97732198 0.97706918 0.97187072 0.97560098\n",
      " 0.98075469 0.98384305 0.974983   0.97943036 0.97328201 0.97695644\n",
      " 0.96820224 0.98462624 0.97372193 0.97072663 0.97257885 0.97832473\n",
      " 0.97566399 0.96613679 0.98111286 0.97491081 0.9795908  0.96668898\n",
      " 0.97996662 0.97919048 0.9757642  0.975086  ]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  CTR_noise_data[col][data[col] == val] = np.mean(target_vals) + np.random.random(target_vals.shape) * 0.02\n",
      "C:\\Users\\Егор\\AppData\\Local\\Temp\\ipykernel_6204\\1194169326.py:7: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  CTR_noise_data[col][data[col] == val] = np.mean(target_vals) + np.random.random(target_vals.shape) * 0.02\n",
      "C:\\Users\\Егор\\AppData\\Local\\Temp\\ipykernel_6204\\1194169326.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  CTR_noise_data[col][data[col] == val] = np.mean(target_vals) + np.random.random(target_vals.shape) * 0.02\n",
      "C:\\Users\\Егор\\AppData\\Local\\Temp\\ipykernel_6204\\1194169326.py:7: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[0.58940694 0.58635669 0.59484947 ... 0.58536633 0.58794193 0.59632398]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  CTR_noise_data[col][data[col] == val] = np.mean(target_vals) + np.random.random(target_vals.shape) * 0.02\n",
      "C:\\Users\\Егор\\AppData\\Local\\Temp\\ipykernel_6204\\1194169326.py:7: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  CTR_noise_data[col][data[col] == val] = np.mean(target_vals) + np.random.random(target_vals.shape) * 0.02\n",
      "C:\\Users\\Егор\\AppData\\Local\\Temp\\ipykernel_6204\\1194169326.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  CTR_noise_data[col][data[col] == val] = np.mean(target_vals) + np.random.random(target_vals.shape) * 0.02\n",
      "C:\\Users\\Егор\\AppData\\Local\\Temp\\ipykernel_6204\\1194169326.py:7: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[0.47912753 0.47477033 0.47481369 ... 0.47595354 0.48257588 0.48382251]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  CTR_noise_data[col][data[col] == val] = np.mean(target_vals) + np.random.random(target_vals.shape) * 0.02\n",
      "C:\\Users\\Егор\\AppData\\Local\\Temp\\ipykernel_6204\\1194169326.py:7: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  CTR_noise_data[col][data[col] == val] = np.mean(target_vals) + np.random.random(target_vals.shape) * 0.02\n",
      "C:\\Users\\Егор\\AppData\\Local\\Temp\\ipykernel_6204\\1194169326.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  CTR_noise_data[col][data[col] == val] = np.mean(target_vals) + np.random.random(target_vals.shape) * 0.02\n",
      "C:\\Users\\Егор\\AppData\\Local\\Temp\\ipykernel_6204\\1194169326.py:7: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[0.48534672 0.47824985 0.48225486 ... 0.48957585 0.49120721 0.49162542]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  CTR_noise_data[col][data[col] == val] = np.mean(target_vals) + np.random.random(target_vals.shape) * 0.02\n",
      "C:\\Users\\Егор\\AppData\\Local\\Temp\\ipykernel_6204\\1194169326.py:7: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  CTR_noise_data[col][data[col] == val] = np.mean(target_vals) + np.random.random(target_vals.shape) * 0.02\n",
      "C:\\Users\\Егор\\AppData\\Local\\Temp\\ipykernel_6204\\1194169326.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  CTR_noise_data[col][data[col] == val] = np.mean(target_vals) + np.random.random(target_vals.shape) * 0.02\n",
      "C:\\Users\\Егор\\AppData\\Local\\Temp\\ipykernel_6204\\1194169326.py:7: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[0.48299547 0.47116137 0.47567099 ... 0.47933852 0.46717041 0.47900072]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  CTR_noise_data[col][data[col] == val] = np.mean(target_vals) + np.random.random(target_vals.shape) * 0.02\n",
      "C:\\Users\\Егор\\AppData\\Local\\Temp\\ipykernel_6204\\1194169326.py:7: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  CTR_noise_data[col][data[col] == val] = np.mean(target_vals) + np.random.random(target_vals.shape) * 0.02\n",
      "C:\\Users\\Егор\\AppData\\Local\\Temp\\ipykernel_6204\\1194169326.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  CTR_noise_data[col][data[col] == val] = np.mean(target_vals) + np.random.random(target_vals.shape) * 0.02\n",
      "C:\\Users\\Егор\\AppData\\Local\\Temp\\ipykernel_6204\\1194169326.py:7: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[0.47654331 0.49054146 0.47548056 ... 0.47531432 0.48198699 0.49405081]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  CTR_noise_data[col][data[col] == val] = np.mean(target_vals) + np.random.random(target_vals.shape) * 0.02\n",
      "C:\\Users\\Егор\\AppData\\Local\\Temp\\ipykernel_6204\\1194169326.py:7: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  CTR_noise_data[col][data[col] == val] = np.mean(target_vals) + np.random.random(target_vals.shape) * 0.02\n",
      "C:\\Users\\Егор\\AppData\\Local\\Temp\\ipykernel_6204\\1194169326.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  CTR_noise_data[col][data[col] == val] = np.mean(target_vals) + np.random.random(target_vals.shape) * 0.02\n",
      "C:\\Users\\Егор\\AppData\\Local\\Temp\\ipykernel_6204\\1194169326.py:7: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[0.69712714 0.69430182 0.69605179 ... 0.70263584 0.70400868 0.69422029]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  CTR_noise_data[col][data[col] == val] = np.mean(target_vals) + np.random.random(target_vals.shape) * 0.02\n",
      "C:\\Users\\Егор\\AppData\\Local\\Temp\\ipykernel_6204\\1194169326.py:7: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  CTR_noise_data[col][data[col] == val] = np.mean(target_vals) + np.random.random(target_vals.shape) * 0.02\n",
      "C:\\Users\\Егор\\AppData\\Local\\Temp\\ipykernel_6204\\1194169326.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  CTR_noise_data[col][data[col] == val] = np.mean(target_vals) + np.random.random(target_vals.shape) * 0.02\n",
      "C:\\Users\\Егор\\AppData\\Local\\Temp\\ipykernel_6204\\1194169326.py:7: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[0.5622319  0.56598092 0.56654355 ... 0.57070929 0.55709809 0.56654835]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  CTR_noise_data[col][data[col] == val] = np.mean(target_vals) + np.random.random(target_vals.shape) * 0.02\n",
      "C:\\Users\\Егор\\AppData\\Local\\Temp\\ipykernel_6204\\1194169326.py:7: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  CTR_noise_data[col][data[col] == val] = np.mean(target_vals) + np.random.random(target_vals.shape) * 0.02\n",
      "C:\\Users\\Егор\\AppData\\Local\\Temp\\ipykernel_6204\\1194169326.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  CTR_noise_data[col][data[col] == val] = np.mean(target_vals) + np.random.random(target_vals.shape) * 0.02\n",
      "C:\\Users\\Егор\\AppData\\Local\\Temp\\ipykernel_6204\\1194169326.py:7: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[0.76503064 0.76476219 0.75772357 0.76940736 0.77396826 0.75812806\n",
      " 0.77305581 0.76371365 0.76428126 0.76490568 0.77003301 0.77037459\n",
      " 0.76086411 0.75802539 0.77266805 0.76574473 0.75728596 0.75896489\n",
      " 0.75795808 0.75686002 0.77405135 0.77300787 0.76778497 0.75959691\n",
      " 0.77234766 0.77487209 0.77290123 0.76127188 0.77048123 0.77414877\n",
      " 0.76526084 0.76539113 0.75943315 0.76423935 0.76538271 0.75723715\n",
      " 0.76737043 0.77503209 0.7582765  0.76018264 0.76142576 0.75958321\n",
      " 0.77339736 0.75557246 0.75633615 0.76670506 0.75990441 0.76128602\n",
      " 0.77499917 0.76867811 0.76197682 0.77329588 0.77090795 0.7646332\n",
      " 0.77427968 0.77201564 0.76809572 0.75959256 0.77314826 0.7587435\n",
      " 0.76578024 0.77002011 0.7585933  0.76215135 0.76981055 0.76019037\n",
      " 0.77222376 0.76330927 0.76264152 0.76351969 0.76963945 0.76067393\n",
      " 0.76837011 0.76873513 0.76601478 0.76981074 0.77314243 0.77097631\n",
      " 0.76343216 0.76526943 0.75768485 0.75650854 0.76186433 0.76301516\n",
      " 0.75754696 0.75905709 0.76267111 0.75884617 0.75970907 0.76269382\n",
      " 0.77178322 0.75995063 0.76988877 0.77364017 0.7661302  0.76792433\n",
      " 0.76471123 0.76399887 0.77279193 0.76138546 0.75790758 0.76601147\n",
      " 0.77459377 0.77326338 0.76346219 0.77039559 0.76262382 0.76706035\n",
      " 0.76990772 0.76504557 0.76149158 0.77139032 0.7731969  0.76251421\n",
      " 0.76299886 0.77525764 0.76116595 0.76778335 0.77416691 0.76925843\n",
      " 0.76212232 0.76437297 0.76946059 0.75806394 0.76952859 0.76108086\n",
      " 0.76040547 0.77155371 0.7720354  0.77216492 0.75769356 0.77059213\n",
      " 0.75696374 0.76088667 0.76952308 0.77240409 0.77471126 0.77485502\n",
      " 0.77250368 0.75567362 0.75988198 0.76794677 0.76744209 0.77040149\n",
      " 0.77140657 0.76385634 0.75701001 0.76459934 0.76610274 0.75843483\n",
      " 0.76799421 0.76714004 0.77361499 0.75916415 0.76987705 0.77009543\n",
      " 0.75924036 0.7643498  0.7612239  0.7668811  0.77275453 0.77049404\n",
      " 0.75987032 0.76117655 0.75936991 0.77171867 0.75603196 0.76994492\n",
      " 0.77200449 0.77067992 0.75966602 0.76277491 0.7721107  0.76547273\n",
      " 0.7725333  0.77244836 0.76739009 0.77367193 0.76543972 0.76484105\n",
      " 0.77504493 0.76647688 0.76012022 0.77394709 0.77391121 0.76258906\n",
      " 0.7690772  0.76893095 0.75691018 0.77014053 0.7589946  0.76621981\n",
      " 0.77148049 0.7652103  0.76969009 0.76952017 0.76865931 0.76334747\n",
      " 0.76587297 0.77248953 0.75910318 0.77217623 0.77062938 0.76353273\n",
      " 0.76152706 0.75928322 0.77437425 0.75948567 0.77024557 0.76828735\n",
      " 0.76062706 0.767359   0.76418613 0.75826701 0.77229905 0.76456532\n",
      " 0.7570802  0.76932533 0.77035503 0.76706221 0.77214873 0.76228885\n",
      " 0.76775484 0.75593436 0.76553657 0.77439817 0.75741354 0.77451937\n",
      " 0.75605196 0.77295102 0.75781186 0.77353001 0.76936982 0.76484389\n",
      " 0.75726419 0.76760557 0.76987578 0.76648194 0.76164226 0.75943047\n",
      " 0.76983982 0.76878953 0.76450594 0.76021601 0.7689823  0.75752974\n",
      " 0.76037867 0.75688806 0.7615808  0.77498865 0.77192144 0.76887299\n",
      " 0.77527443 0.75774421 0.76339639 0.75545206 0.75887658 0.76945788\n",
      " 0.7638247  0.76048891 0.76720675 0.77124488 0.76750034 0.75728417\n",
      " 0.77251375 0.76564144 0.76118884 0.75605599 0.77248127 0.7559902\n",
      " 0.75747245 0.76241601 0.76878927 0.76038588 0.76286706 0.75548257\n",
      " 0.77333382 0.77421824 0.77378867 0.76465069 0.77430426 0.76557615\n",
      " 0.77473175 0.77506331 0.76948451 0.75548061 0.76669881 0.76578391\n",
      " 0.76756926 0.75538912 0.77432738 0.75919816 0.76364954 0.77401553\n",
      " 0.76274582 0.76293442 0.75794061 0.7697032  0.75906202 0.76269751\n",
      " 0.76288282 0.76196943 0.76868441 0.7633801  0.77439283 0.76954124\n",
      " 0.76848723 0.75962502 0.76341241 0.76237151 0.7627561  0.76780186\n",
      " 0.76593512 0.75861441 0.77252355 0.76146123 0.77505849 0.77524135\n",
      " 0.7570642  0.76855749 0.76396329 0.76084906 0.76136221 0.76164274\n",
      " 0.77166657 0.77009622 0.76670086]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  CTR_noise_data[col][data[col] == val] = np.mean(target_vals) + np.random.random(target_vals.shape) * 0.02\n",
      "C:\\Users\\Егор\\AppData\\Local\\Temp\\ipykernel_6204\\1194169326.py:7: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  CTR_noise_data[col][data[col] == val] = np.mean(target_vals) + np.random.random(target_vals.shape) * 0.02\n",
      "C:\\Users\\Егор\\AppData\\Local\\Temp\\ipykernel_6204\\1194169326.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  CTR_noise_data[col][data[col] == val] = np.mean(target_vals) + np.random.random(target_vals.shape) * 0.02\n",
      "C:\\Users\\Егор\\AppData\\Local\\Temp\\ipykernel_6204\\1194169326.py:7: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[0.48517114 0.4994523  0.49350834 ... 0.48624921 0.49684424 0.48887489]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  CTR_noise_data[col][data[col] == val] = np.mean(target_vals) + np.random.random(target_vals.shape) * 0.02\n",
      "C:\\Users\\Егор\\AppData\\Local\\Temp\\ipykernel_6204\\1194169326.py:7: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  CTR_noise_data[col][data[col] == val] = np.mean(target_vals) + np.random.random(target_vals.shape) * 0.02\n",
      "C:\\Users\\Егор\\AppData\\Local\\Temp\\ipykernel_6204\\1194169326.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  CTR_noise_data[col][data[col] == val] = np.mean(target_vals) + np.random.random(target_vals.shape) * 0.02\n",
      "C:\\Users\\Егор\\AppData\\Local\\Temp\\ipykernel_6204\\1194169326.py:7: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[0.54225734 0.53482947 0.53791193 ... 0.54239269 0.54138611 0.5354388 ]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  CTR_noise_data[col][data[col] == val] = np.mean(target_vals) + np.random.random(target_vals.shape) * 0.02\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ps_ind_01</th>\n",
       "      <th>ps_ind_02_cat</th>\n",
       "      <th>ps_ind_03</th>\n",
       "      <th>ps_ind_04_cat</th>\n",
       "      <th>ps_ind_05_cat</th>\n",
       "      <th>ps_ind_06_bin</th>\n",
       "      <th>ps_ind_07_bin</th>\n",
       "      <th>ps_ind_08_bin</th>\n",
       "      <th>ps_ind_09_bin</th>\n",
       "      <th>ps_ind_10_bin</th>\n",
       "      <th>...</th>\n",
       "      <th>ps_calc_11</th>\n",
       "      <th>ps_calc_12</th>\n",
       "      <th>ps_calc_13</th>\n",
       "      <th>ps_calc_14</th>\n",
       "      <th>ps_calc_15_bin</th>\n",
       "      <th>ps_calc_16_bin</th>\n",
       "      <th>ps_calc_17_bin</th>\n",
       "      <th>ps_calc_18_bin</th>\n",
       "      <th>ps_calc_19_bin</th>\n",
       "      <th>ps_calc_20_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.998215</td>\n",
       "      <td>0.510005</td>\n",
       "      <td>4.483870</td>\n",
       "      <td>0.510011</td>\n",
       "      <td>0.510012</td>\n",
       "      <td>0.351100</td>\n",
       "      <td>0.295375</td>\n",
       "      <td>0.175920</td>\n",
       "      <td>0.177605</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>...</td>\n",
       "      <td>5.443865</td>\n",
       "      <td>1.443745</td>\n",
       "      <td>2.873590</td>\n",
       "      <td>7.544455</td>\n",
       "      <td>0.123355</td>\n",
       "      <td>0.630875</td>\n",
       "      <td>0.553405</td>\n",
       "      <td>0.287530</td>\n",
       "      <td>0.345000</td>\n",
       "      <td>0.152800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.017199</td>\n",
       "      <td>0.016993</td>\n",
       "      <td>2.739255</td>\n",
       "      <td>0.021214</td>\n",
       "      <td>0.050562</td>\n",
       "      <td>0.477315</td>\n",
       "      <td>0.456212</td>\n",
       "      <td>0.380753</td>\n",
       "      <td>0.382181</td>\n",
       "      <td>0.021674</td>\n",
       "      <td>...</td>\n",
       "      <td>2.342462</td>\n",
       "      <td>1.201163</td>\n",
       "      <td>1.692875</td>\n",
       "      <td>2.745287</td>\n",
       "      <td>0.328845</td>\n",
       "      <td>0.482569</td>\n",
       "      <td>0.497141</td>\n",
       "      <td>0.452612</td>\n",
       "      <td>0.475369</td>\n",
       "      <td>0.359796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.494915</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.486218</td>\n",
       "      <td>0.480547</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.501811</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.495028</td>\n",
       "      <td>0.486405</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.508331</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.503795</td>\n",
       "      <td>0.492235</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.514139</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.525746</td>\n",
       "      <td>0.498071</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.931036</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.984071</td>\n",
       "      <td>0.717421</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ps_ind_01  ps_ind_02_cat      ps_ind_03  ps_ind_04_cat  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean        1.998215       0.510005       4.483870       0.510011   \n",
       "std         2.017199       0.016993       2.739255       0.021214   \n",
       "min         0.000000       0.494915       0.000000       0.486218   \n",
       "25%         0.000000       0.501811       2.000000       0.495028   \n",
       "50%         1.000000       0.508331       4.000000       0.503795   \n",
       "75%         3.000000       0.514139       7.000000       0.525746   \n",
       "max         7.000000       0.931036      11.000000       0.984071   \n",
       "\n",
       "       ps_ind_05_cat  ps_ind_06_bin  ps_ind_07_bin  ps_ind_08_bin  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean        0.510012       0.351100       0.295375       0.175920   \n",
       "std         0.050562       0.477315       0.456212       0.380753   \n",
       "min         0.480547       0.000000       0.000000       0.000000   \n",
       "25%         0.486405       0.000000       0.000000       0.000000   \n",
       "50%         0.492235       0.000000       0.000000       0.000000   \n",
       "75%         0.498071       1.000000       1.000000       0.000000   \n",
       "max         0.717421       1.000000       1.000000       1.000000   \n",
       "\n",
       "       ps_ind_09_bin  ps_ind_10_bin  ...     ps_calc_11     ps_calc_12  \\\n",
       "count  200000.000000  200000.000000  ...  200000.000000  200000.000000   \n",
       "mean        0.177605       0.000470  ...       5.443865       1.443745   \n",
       "std         0.382181       0.021674  ...       2.342462       1.201163   \n",
       "min         0.000000       0.000000  ...       0.000000       0.000000   \n",
       "25%         0.000000       0.000000  ...       4.000000       1.000000   \n",
       "50%         0.000000       0.000000  ...       5.000000       1.000000   \n",
       "75%         0.000000       0.000000  ...       7.000000       2.000000   \n",
       "max         1.000000       1.000000  ...      18.000000       8.000000   \n",
       "\n",
       "          ps_calc_13     ps_calc_14  ps_calc_15_bin  ps_calc_16_bin  \\\n",
       "count  200000.000000  200000.000000   200000.000000   200000.000000   \n",
       "mean        2.873590       7.544455        0.123355        0.630875   \n",
       "std         1.692875       2.745287        0.328845        0.482569   \n",
       "min         0.000000       0.000000        0.000000        0.000000   \n",
       "25%         2.000000       6.000000        0.000000        0.000000   \n",
       "50%         3.000000       7.000000        0.000000        1.000000   \n",
       "75%         4.000000       9.000000        0.000000        1.000000   \n",
       "max        13.000000      22.000000        1.000000        1.000000   \n",
       "\n",
       "       ps_calc_17_bin  ps_calc_18_bin  ps_calc_19_bin  ps_calc_20_bin  \n",
       "count   200000.000000   200000.000000   200000.000000   200000.000000  \n",
       "mean         0.553405        0.287530        0.345000        0.152800  \n",
       "std          0.497141        0.452612        0.475369        0.359796  \n",
       "min          0.000000        0.000000        0.000000        0.000000  \n",
       "25%          0.000000        0.000000        0.000000        0.000000  \n",
       "50%          1.000000        0.000000        0.000000        0.000000  \n",
       "75%          1.000000        1.000000        1.000000        0.000000  \n",
       "max          1.000000        1.000000        1.000000        1.000000  \n",
       "\n",
       "[8 rows x 57 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CTR_noise_data = data.copy()\n",
    "\n",
    "for col in categories:\n",
    "    unique_vals = np.unique(data[col])\n",
    "    for val in unique_vals:\n",
    "        target_vals = target[data[col] == val]\n",
    "        CTR_noise_data[col][data[col] == val] = np.mean(target_vals) + np.random.random(target_vals.shape) * 0.02\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(normalize(CTR_noise_data), target, test_size=0.5)\n",
    "CTR_noise_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5925\n",
      "Precision: 0.5997\n",
      "Recall: 0.5623\n",
      "F1: 0.5804\n"
     ]
    }
   ],
   "source": [
    "display_metrics(evaluate_model(X_train, y_train, X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ps_ind_01</th>\n",
       "      <th>ps_ind_02_cat</th>\n",
       "      <th>ps_ind_03</th>\n",
       "      <th>ps_ind_04_cat</th>\n",
       "      <th>ps_ind_05_cat</th>\n",
       "      <th>ps_ind_06_bin</th>\n",
       "      <th>ps_ind_07_bin</th>\n",
       "      <th>ps_ind_08_bin</th>\n",
       "      <th>ps_ind_09_bin</th>\n",
       "      <th>ps_ind_10_bin</th>\n",
       "      <th>...</th>\n",
       "      <th>ps_calc_11</th>\n",
       "      <th>ps_calc_12</th>\n",
       "      <th>ps_calc_13</th>\n",
       "      <th>ps_calc_14</th>\n",
       "      <th>ps_calc_15_bin</th>\n",
       "      <th>ps_calc_16_bin</th>\n",
       "      <th>ps_calc_17_bin</th>\n",
       "      <th>ps_calc_18_bin</th>\n",
       "      <th>ps_calc_19_bin</th>\n",
       "      <th>ps_calc_20_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.998215</td>\n",
       "      <td>0.499997</td>\n",
       "      <td>4.483870</td>\n",
       "      <td>0.499997</td>\n",
       "      <td>0.499984</td>\n",
       "      <td>0.351100</td>\n",
       "      <td>0.295375</td>\n",
       "      <td>0.175920</td>\n",
       "      <td>0.177605</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>...</td>\n",
       "      <td>5.443865</td>\n",
       "      <td>1.443745</td>\n",
       "      <td>2.873590</td>\n",
       "      <td>7.544455</td>\n",
       "      <td>0.123355</td>\n",
       "      <td>0.630875</td>\n",
       "      <td>0.553405</td>\n",
       "      <td>0.287530</td>\n",
       "      <td>0.345000</td>\n",
       "      <td>0.152800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.017199</td>\n",
       "      <td>0.072264</td>\n",
       "      <td>2.739255</td>\n",
       "      <td>0.072364</td>\n",
       "      <td>0.085039</td>\n",
       "      <td>0.477315</td>\n",
       "      <td>0.456212</td>\n",
       "      <td>0.380753</td>\n",
       "      <td>0.382181</td>\n",
       "      <td>0.021674</td>\n",
       "      <td>...</td>\n",
       "      <td>2.342462</td>\n",
       "      <td>1.201163</td>\n",
       "      <td>1.692875</td>\n",
       "      <td>2.745287</td>\n",
       "      <td>0.328845</td>\n",
       "      <td>0.482569</td>\n",
       "      <td>0.497141</td>\n",
       "      <td>0.452612</td>\n",
       "      <td>0.475369</td>\n",
       "      <td>0.359796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.422759</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.412820</td>\n",
       "      <td>0.406339</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.422759</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.406339</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.565613</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.555677</td>\n",
       "      <td>0.549196</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.565618</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.555677</td>\n",
       "      <td>0.549196</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.797091</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ps_ind_01  ps_ind_02_cat      ps_ind_03  ps_ind_04_cat  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean        1.998215       0.499997       4.483870       0.499997   \n",
       "std         2.017199       0.072264       2.739255       0.072364   \n",
       "min         0.000000       0.422759       0.000000       0.412820   \n",
       "25%         0.000000       0.422759       2.000000       0.428571   \n",
       "50%         1.000000       0.565613       4.000000       0.555677   \n",
       "75%         3.000000       0.565618       7.000000       0.555677   \n",
       "max         7.000000       1.000000      11.000000       1.000000   \n",
       "\n",
       "       ps_ind_05_cat  ps_ind_06_bin  ps_ind_07_bin  ps_ind_08_bin  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean        0.499984       0.351100       0.295375       0.175920   \n",
       "std         0.085039       0.477315       0.456212       0.380753   \n",
       "min         0.406339       0.000000       0.000000       0.000000   \n",
       "25%         0.406339       0.000000       0.000000       0.000000   \n",
       "50%         0.549196       0.000000       0.000000       0.000000   \n",
       "75%         0.549196       1.000000       1.000000       0.000000   \n",
       "max         0.797091       1.000000       1.000000       1.000000   \n",
       "\n",
       "       ps_ind_09_bin  ps_ind_10_bin  ...     ps_calc_11     ps_calc_12  \\\n",
       "count  200000.000000  200000.000000  ...  200000.000000  200000.000000   \n",
       "mean        0.177605       0.000470  ...       5.443865       1.443745   \n",
       "std         0.382181       0.021674  ...       2.342462       1.201163   \n",
       "min         0.000000       0.000000  ...       0.000000       0.000000   \n",
       "25%         0.000000       0.000000  ...       4.000000       1.000000   \n",
       "50%         0.000000       0.000000  ...       5.000000       1.000000   \n",
       "75%         0.000000       0.000000  ...       7.000000       2.000000   \n",
       "max         1.000000       1.000000  ...      18.000000       8.000000   \n",
       "\n",
       "          ps_calc_13     ps_calc_14  ps_calc_15_bin  ps_calc_16_bin  \\\n",
       "count  200000.000000  200000.000000   200000.000000   200000.000000   \n",
       "mean        2.873590       7.544455        0.123355        0.630875   \n",
       "std         1.692875       2.745287        0.328845        0.482569   \n",
       "min         0.000000       0.000000        0.000000        0.000000   \n",
       "25%         2.000000       6.000000        0.000000        0.000000   \n",
       "50%         3.000000       7.000000        0.000000        1.000000   \n",
       "75%         4.000000       9.000000        0.000000        1.000000   \n",
       "max        13.000000      22.000000        1.000000        1.000000   \n",
       "\n",
       "       ps_calc_17_bin  ps_calc_18_bin  ps_calc_19_bin  ps_calc_20_bin  \n",
       "count   200000.000000   200000.000000   200000.000000   200000.000000  \n",
       "mean         0.553405        0.287530        0.345000        0.152800  \n",
       "std          0.497141        0.452612        0.475369        0.359796  \n",
       "min          0.000000        0.000000        0.000000        0.000000  \n",
       "25%          0.000000        0.000000        0.000000        0.000000  \n",
       "50%          1.000000        0.000000        0.000000        0.000000  \n",
       "75%          1.000000        1.000000        1.000000        0.000000  \n",
       "max          1.000000        1.000000        1.000000        1.000000  \n",
       "\n",
       "[8 rows x 57 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def min_val(x, y):\n",
    "    if x < y:\n",
    "        return x\n",
    "    return y\n",
    "\n",
    "fold_data = data.copy()\n",
    "\n",
    "def calc_out_of_fold_mean(index, cumulative_sum, fold_len, total_len):\n",
    "    fold_index = index // fold_len\n",
    "    left_idx = fold_index * fold_len\n",
    "    right_idx = min_val(total_len, (fold_index + 1) * fold_len)\n",
    "    full_sum = cumulative_sum[-1]\n",
    "    fold_sum_val = cumulative_sum[right_idx] - cumulative_sum[left_idx]\n",
    "    out_fold_sum = full_sum - fold_sum_val\n",
    "    out_fold_count = total_len - (right_idx - left_idx)\n",
    "    if out_fold_count == 0:\n",
    "        return full_sum / total_len\n",
    "    return out_fold_sum / out_fold_count\n",
    "\n",
    "num_folds = 8\n",
    "\n",
    "for col in categories:\n",
    "    result = []\n",
    "    unique_vals = np.unique(data[col])\n",
    "    cumulative_sums = {}\n",
    "    counters = {}\n",
    "\n",
    "    for val in unique_vals:\n",
    "        target_vals = np.array(target[data[col] == val])\n",
    "        cumulative_sums[val] = np.hstack(([0], np.cumsum(target_vals)))\n",
    "\n",
    "    for curr_val in data[col]:\n",
    "        if curr_val not in counters:\n",
    "            counters[curr_val] = 0\n",
    "        total_count = len(cumulative_sums[curr_val]) - 1\n",
    "        fold_length = (total_count + num_folds - 1) // num_folds\n",
    "        result.append(calc_out_of_fold_mean(counters[curr_val], cumulative_sums[curr_val], fold_length, total_count))\n",
    "        counters[curr_val] += 1\n",
    "\n",
    "    fold_data[col] = result\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(normalize(fold_data), target, test_size=0.5)\n",
    "fold_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9997\n",
      "Precision: 0.9997\n",
      "Recall: 0.9997\n",
      "F1: 0.9997\n"
     ]
    }
   ],
   "source": [
    "display_metrics(evaluate_model(X_train, y_train, X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CIXbvzlWaRLX"
   },
   "source": [
    "__Вывод:__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
